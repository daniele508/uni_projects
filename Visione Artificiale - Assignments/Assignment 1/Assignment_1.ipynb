{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c00269",
   "metadata": {},
   "source": [
    "Per calibrare una camera si stima una matrice, chiamata P, che fa corrispondere un punto 3D del mondo ad un punto 2D sull'immagine\n",
    "\n",
    "Si utilizzano le librerie python ```OpenCV```, che permette di manipolare le immagini, e ```numpy```, che manipola dati in forma vettoriale e matriciale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8a2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cc8f4c9",
   "metadata": {},
   "source": [
    "Si definisce il metodo ```acquisizione``` che permette di acquisire delle immagini da una videocamera, visualizzando l'ultima scattata\n",
    "\n",
    "Viene utilizzato per acquisire un'immagine di un pattern di cui si conoscono le dimensioni, da cui verranno scelti dei punti 3D e 2D per calibrare la camera. Per questo motivo viene scelto un cubo le cui facce sono costituite da scacchiere: \n",
    "\n",
    "![cubo](images/object.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cb5bb0-c593-49a1-bf50-6a538ccff568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisizione():\n",
    "    ID = 0 # webcam\n",
    "    src = 'rtsp://CV2023:Studente123@147.163.26.184:554/Streaming/Channels/101'\n",
    "    #src = 'rtsp://CV2023:Studente123@147.163.26.182:554/Streaming/Channels/101'\n",
    "\n",
    "    #video = cv2.VideoCapture(src)\n",
    "    video = cv2.VideoCapture(ID)\n",
    "\n",
    "    print(video)\n",
    "\n",
    "    if video is None or not video.isOpened():\n",
    "        raise IOError(\"video not found\")\n",
    "    \n",
    "    else:\n",
    "        print(\"frame width \", video.get(cv2.CAP_PROP_FRAME_WIDTH ))\n",
    "        print(\"frame height \", video.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n",
    "        print(\"frame rate \", video.get(cv2.CAP_PROP_FPS ))\n",
    "        ret, img = video.read()\n",
    "        key = ''\n",
    "        i=1\n",
    "\n",
    "        while ret and key!=ord('q'):\n",
    "            cv2.imshow(\"frame\", img)\n",
    "            key = cv2.waitKey(1)\n",
    "            ret, img = video.read()\n",
    "            if key==ord('a'):\n",
    "                string=\"images/image_\"+str(i)+\".png\"\n",
    "                cv2.imwrite(string, img)\n",
    "                i+=1\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "    \n",
    "    if i-1==0:\n",
    "        return False, None\n",
    "    else:\n",
    "        img=cv2.imread(\"images/image_\"+str(i-1)+\".png\")\n",
    "        cv2.imshow(\"img\",img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return True, img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f0d17ed",
   "metadata": {},
   "source": [
    "Si definiscono i punti 3D, del mondo, e 2D, dell'immagine, del pattern precedetemente fotografato. \n",
    "\n",
    "Essi saranno della forma: $P_{w}=[x_{w}, y_{w}, z_{w}]^T$ e $P_{I}=[u_{i}, v_{i}]^T$\n",
    "\n",
    "Una volta definiti vengono mostrati evidenziando un piccolo cerchio corrispondente al punto direttamente sull'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d774560-e25f-4d1f-8296-2637a7281569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_punti_c(n):\n",
    "\n",
    "    #3D points\n",
    "    points = np.zeros((n,3), np.float32)\n",
    "\n",
    "    points[0,:]=[0,0,0]\n",
    "\n",
    "    points[1,:]=[5,0,7]\n",
    "    points[2,:]=[3,0,4]\n",
    "\n",
    "    points[3,:]=[0,5,3]\n",
    "\n",
    "    points[4,:]=[2,3,9]\n",
    "    points[5,:]=[6,3,9]\n",
    "\n",
    "    if n>6:\n",
    "        points[6,:]=[2,0,6]\n",
    "        points[7,:]=[5,0,2]\n",
    "\n",
    "        points[8,:]=[0,4,2]\n",
    "        points[9,:]=[0,1,7]\n",
    "\n",
    "        points[10,:]=[5,1,9]\n",
    "        points[11,:]=[4,4,9]\n",
    "\n",
    "    if n>12:\n",
    "        points[12,:]=[2,0,1]\n",
    "        points[13,:]=[4,0,5]\n",
    "        points[14,:]=[6,0,8]\n",
    "        points[15,:]=[3,0,7]\n",
    "\n",
    "        points[16,:]=[0,2,4]\n",
    "        points[17,:]=[0,4,7]\n",
    "        points[18,:]=[0,4,0]\n",
    "        points[19,:]=[0,5,4]\n",
    "\n",
    "        points[20,:]=[3,2,9]\n",
    "        points[21,:]=[5,2,9]\n",
    "        points[22,:]=[2,1,9]\n",
    "        points[23,:]=[1,4,9]\n",
    "\n",
    "    #2D points\n",
    "    imgp = np.zeros((n,2), np.float32)\n",
    "\n",
    "    imgp[0,:]=[626,520]\n",
    "\n",
    "    imgp[1,:]=[762,308]\n",
    "    imgp[2,:]=[705,398]\n",
    "\n",
    "    imgp[3,:]=[580,356]\n",
    "\n",
    "    imgp[4,:]=[641,229]\n",
    "    imgp[5,:]=[727,210]\n",
    "\n",
    "    if n>6:\n",
    "        imgp[6,:]=[692,354]\n",
    "        imgp[7,:]=[737,430]\n",
    "\n",
    "        imgp[8,:]=[554,417]\n",
    "        imgp[9,:]=[627,329]\n",
    "\n",
    "        imgp[10,:]=[748,236]\n",
    "        imgp[11,:]=[665,209]\n",
    "\n",
    "    if n>12:\n",
    "        imgp[12,:]=[672,479]\n",
    "        imgp[13,:]=[731,366]\n",
    "        imgp[14,:]=[787,275]\n",
    "        imgp[15,:]=[720,320]\n",
    "        \n",
    "        imgp[16,:]=[596,395]\n",
    "        imgp[17,:]=[566,290]\n",
    "        imgp[18,:]=[551,462]\n",
    "        imgp[19,:]=[541,355]\n",
    "\n",
    "        imgp[20,:]=[684,235]\n",
    "        imgp[21,:]=[727,225]\n",
    "        imgp[22,:]=[683,253]\n",
    "        imgp[23,:]=[598,224]\n",
    "\n",
    "    return points, imgp\n",
    "\n",
    "def mostra_punti(img, imgp):\n",
    "    \n",
    "    for p in imgp:\n",
    "        img = cv2.circle(img, p.astype(np.int32), 3, (0, 0, 255) )\n",
    "\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee0f5371",
   "metadata": {},
   "source": [
    "Si definisce il metodo ```calibrateDLT``` che applica il metodo Direct Linear Transofrmation per calibrare la camera, cioè stimare la matrice di proiezione $P$, da cui si deriva la matrice $K$ dei parametri intrinseci della camera.\n",
    "\n",
    "La matrice $P$ trova le corrispondenze tra punti 3D e 2D attraverso il seguente sistema:\n",
    "\n",
    "![sistema](images/formule/eq.png)\n",
    "\n",
    "che si riscrive nella forma:\n",
    "\n",
    "![equazioni](images/formule/eq2.png)\n",
    "\n",
    "Si ottengono così due equazioni per ogni punto. Esplicitando le variabili $p_{ij}$ si possono calcolare gli elementi della matrice $P$ attraverso il nuovo sistema:\n",
    "\n",
    "![sistema2](images/formule/all_eq.png)\n",
    "\n",
    "Il problema si riduce a dover risolvere un sistema del tipo $Ap=0$\n",
    "\n",
    "Imponendo che $||p||_{2}=0$, si vuole trovare il vettore $p$ tale che $Ap$ sia più vicino a $0$ e che la norma quadra di $p$ sia più vicina a $1$.\n",
    "\n",
    "Quindi il problema di trasforma in uno di minimizzazione: \n",
    "\n",
    "$min_{p}\\;||Ap||_{2}-\\lambda||p||_{2}$\n",
    "\n",
    "che è equivalente a scrivere \n",
    "\n",
    "$min_{p}\\;p^TA^TAp-\\lambda p^Tp$.\n",
    "\n",
    "Per risolvere il problema si calcola il gradiente e lo si impone uguale a $0$: \n",
    "\n",
    "$2A^TAp-2\\lambda p=0$\n",
    "\n",
    "$A^TAp=\\lambda p$ \n",
    "\n",
    "che corrisponde al calcolo degli autovalori.\n",
    "\n",
    "Quidi si vuole trovare l'autovettore $p$ che corrisponde all'autovalore più piccolo della matrice $A^TA$\n",
    "\n",
    "Ciò può essere fatto attraverso la decomposizione $SVD$ poiché $A=U\\Sigma V^{T} \\;\\Rightarrow\\; A^{T}A=V\\Sigma U^{T}U\\Sigma V \\;\\Rightarrow\\; A^{T}AV=V\\Sigma^{2}$ dove $V$ è la matrice degli autovettori e $\\Sigma^{2}$ è la matrice degli autovalori disposti sulla diagonale.\n",
    "\n",
    "Dato che il metodo ```svd``` della libreria ```numpy``` ordina gli autovalori in modo decrescente, per l'autovettore associato all'autovalore più piccolo basterà considerare l'ultima riga della matrice $V$\n",
    "\n",
    "La matrice $P$ si può esprimere come $P=K[Rt]$, dove $K$ è la matrice $3\\times3$ dei parametri intriseci della camera ed $[Rt]$ quella  $3\\times4$ dei parametri estrinseci, dove a sua volta $R$ è la matrice $3\\times3$ di rotazione e $t$ è il vettore di traslazione.\n",
    "\n",
    "Quindi si possono ottenere $K$ e $R$ fattorizzando $P_{1:3}$: \n",
    "\n",
    "![sub](images/formule/subMat.png)\n",
    "\n",
    "Si potrebbe applicare una fattorizzazione $QR$, ma in questo caso la matrice $K$ è triangolare superiore ed $R$ è ortogonale. Perciò è più appropriata la fattorizzazione $RQ$, che può essere ottenuta fattorizzando $(P_{1:3})^{-1}$ in $QR$. Infatti $(P_{1:3})^{-1})(KR)^{-1} = R^{-1}K^{-1}$\n",
    "\n",
    "La libreria ```numpy``` provvede i metodi ```inv``` e ```qr``` rispettivamente per invertire una matrice e per effettuare la fattorizzazione $QR$\n",
    "\n",
    "Infine si deve scalare la matrice $K$ per l'elemento $K_{3,3}$ in modo da ottenere $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996ac092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrateDLT(points, img_p):\n",
    "    \n",
    "    r,c=points.shape\n",
    "    A=np.zeros((r*2, 12), np.int32)\n",
    "\n",
    "    #Inizializzo la matrice A\n",
    "    i=0\n",
    "    for p in points:\n",
    "        p_a=np.append(p, 1)\n",
    "        for j in range(2):\n",
    "            A[i, 0:4]=(1-j)*p_a\n",
    "            A[i, 4:8]=(j)*p_a\n",
    "            A[i, 8:12]=-img_p[i//2, j]*p_a\n",
    "            i+=1\n",
    "\n",
    "    #Ricavo l'autovettore dall'autovalore più piccolo\n",
    "    AtA=np.matmul(A.T, A)\n",
    "    U, S, V=np.linalg.svd(AtA)\n",
    "    P=V[11,:]\n",
    "    \n",
    "    #Ottengo la matrice P\n",
    "    P=P.reshape(3,4)\n",
    "\n",
    "    #Scarto l'ultima colonna\n",
    "    P_13=P[:,0:3]\n",
    "\n",
    "    #Ricavo K da P\n",
    "    Pinv=np.linalg.inv(P_13)\n",
    "    Q, R=np.linalg.qr(Pinv)\n",
    "    K=np.linalg.inv(R)\n",
    "    K=abs(K)\n",
    "        \n",
    "    return K, P,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c5874df",
   "metadata": {},
   "source": [
    "La libreria ```OpenCV``` disponde del metodo ```calibrateCamera``` che anch'esso stima la matrice $K$ a partire da una inizializzata dal metodo ```initialize_K```. Per verificare la bontà della matrice $K$ stimata dal metodo precedentemente dichiarato, si calcolano le differenze in valore assoluto con i parametri stimati dalla libreria ```OpenCV``` attraverso il metodo ```compute_absdiff```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59619b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_K(shape):\n",
    "    # initial guess of K\n",
    "    K = np.zeros((3,3))\n",
    "\n",
    "    K[0,0]=500\n",
    "    K[1,1]=500\n",
    "    K[2,2]=1\n",
    "    K[0,2]=shape[0]/2\n",
    "    K[1,2]=shape[1]/2\n",
    "    return K\n",
    "\n",
    "def compute_absdiff(K, K2):\n",
    "    absdiff=[]\n",
    "    for i in range(2):\n",
    "        for j in range(i, 3):\n",
    "            if i==1 and j==1:\n",
    "                absdiff.append(abs(K[i,j]/(16/9)-K2[i,j]/(16/9)))\n",
    "            else:\n",
    "                absdiff.append(abs(K[i,j]-K2[i,j]))\n",
    "    \n",
    "    return absdiff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2a8e0a2",
   "metadata": {},
   "source": [
    "Dopo aver stimato la matrice di proiezione, la si può utilizzare per riproiettare tutti i punti 3D del cubo e verificare a quali punti 2D sull'immagine corrispondono. Il metodo ```punti_cubo``` restituisce tutti i punti $p_{w}^{(i)}=[x_{w}^{(i)}, y_{w}^{(i)}, z_{w}^{(i)}]^T$ del cubo, utilizzati poi dal metodo ```proietta``` che, sfruttando la matrice $P$ e la relazione \n",
    "\n",
    "![sistema](images/formule/eq.png)\n",
    "\n",
    "restituisce i punti $p_{im}^{(i)}=[u_{im}^{(i)}, v_{im}^{(i)}]^T$ corrispondenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c700b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punti_cubo():\n",
    "    points=np.array([[0,0,0]])\n",
    "\n",
    "    for x in range(8):\n",
    "        for y in range(6):\n",
    "            points=np.append(points, [[x,y,9]], axis=0)\n",
    "\n",
    "    for z in range(10):\n",
    "          for y in range(6):\n",
    "               points=np.append(points, [[0,y,z]], axis=0)\n",
    "\n",
    "    for x in range(8):\n",
    "          for z in range(10):\n",
    "               points=np.append(points, [[x,0,z]], axis=0)\n",
    "\n",
    "    return points\n",
    "\n",
    "def proietta(points, P):\n",
    "    r,c=points.shape\n",
    "    points=np.append(points, np.ones((r,1)), axis=1)\n",
    "    imgpoints=np.zeros((r, 3), np.float32)\n",
    "    \n",
    "    i=0\n",
    "    for p in points:\n",
    "            imgpoints[i,:]=np.matmul(P,p)\n",
    "            imgpoints[i,0]=imgpoints[i,0]/imgpoints[i,2]\n",
    "            imgpoints[i,1]=imgpoints[i,1]/imgpoints[i,2]\n",
    "            i+=1\n",
    "    \n",
    "    return imgpoints[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdd6307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 000002138D858F10>\n",
      "frame width  640.0\n",
      "frame height  480.0\n",
      "frame rate  30.0\n"
     ]
    }
   ],
   "source": [
    "ret=False\n",
    "ret, img = acquisizione()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e38eca1",
   "metadata": {},
   "source": [
    "Vengono richiamati i metodi dichiarati precedentemente per acquisire un'immagine di un pattern, definire dei punti 3D e quelli 2D corrispondenti, stimare le matrici $P$ e $K$, conforntare i parametri di $K$ con quelli stimati dalla libreria ```OpenCV```, ricavare tutti i punti 3D del pattern, ricavare quelli 2D corrispondenti e mostrarli.\n",
    "\n",
    "Tutto il processo viene ripetuto per un insieme sempre crescente di punti, cioè di 6, 12 e 24 punti, affinchè migliori la stima delle matrici. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6949e907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=\n",
      " [[ 98.87519189   8.95411768 689.53323621]\n",
      " [  0.         116.81829714 249.84394197]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "K2=\n",
      " [[131.11628034   0.         608.94271549]\n",
      " [  0.         243.45168119 538.50852579]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "------------------------------------------\n",
      "Differenze parametri stimati con 6 punti:\n",
      "\tfx\t=\t32.241088\n",
      "\ts\t=\t8.954118\n",
      "\tcx\t=\t80.590521\n",
      "\tfy\t=\t71.231279\n",
      "\tcy\t=\t288.664584\n",
      "\ta\t=\t16:9\n",
      "------------------------------------------\n",
      "K=\n",
      " [[801.17730599  33.66238643 562.40000341]\n",
      " [  0.         892.17269405 307.48427299]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "K2=\n",
      " [[692.65051979   0.         460.68953026]\n",
      " [  0.         749.45875793 480.10957946]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "------------------------------------------\n",
      "Differenze parametri stimati con 12 punti:\n",
      "\tfx\t=\t108.526786\n",
      "\ts\t=\t33.662386\n",
      "\tcx\t=\t101.710473\n",
      "\tfy\t=\t80.276589\n",
      "\tcy\t=\t172.625306\n",
      "\ta\t=\t16:9\n",
      "------------------------------------------\n",
      "K=\n",
      " [[1.01511558e+03 2.19763208e+01 7.02697394e+02]\n",
      " [0.00000000e+00 1.04912639e+03 4.99774845e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]] \n",
      "\n",
      "K2=\n",
      " [[811.63059488   0.         397.28098764]\n",
      " [  0.         830.00277689 467.01808978]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "------------------------------------------\n",
      "Differenze parametri stimati con 24 punti:\n",
      "\tfx\t=\t203.484984\n",
      "\ts\t=\t21.976321\n",
      "\tcx\t=\t305.416407\n",
      "\tfy\t=\t123.257032\n",
      "\tcy\t=\t32.756755\n",
      "\ta\t=\t16:9\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not ret:\n",
    "    img=cv2.imread(\"images/pattern.png\")\n",
    "\n",
    "for n in [6,12,24]:\n",
    "\n",
    "    #Definizione dei punti 3D e 2D\n",
    "    points, imgp = def_punti_c(n)\n",
    "    mostra_punti(img.copy(), imgp)\n",
    "\n",
    "    #Calibrazione della camera, ricavo K\n",
    "    K, P = calibrateDLT(points, imgp)\n",
    "\n",
    "    #Scalo K affinché l'elemento 3,3 sia uguale a 1\n",
    "    s=1/K[2,2]\n",
    "    Ks=s*K\n",
    "\n",
    "    print(\"K=\\n\",Ks, \"\\n\")\n",
    "\n",
    "    #Calibro la camera con il metodo di OpenCV\n",
    "    K2=initialize_K(img.shape)\n",
    "    ret, K2, dist, Rs, ts = cv2.calibrateCamera([points], [imgp], img.shape[0:2], K2, None, flags=cv2.CALIB_USE_INTRINSIC_GUESS|cv2.CALIB_FIX_S1_S2_S3_S4| cv2.CALIB_ZERO_TANGENT_DIST| cv2.CALIB_FIX_K2 | cv2.CALIB_FIX_K3 )\n",
    "    print(\"K2=\\n\",K2, \"\\n\")\n",
    "\n",
    "    #Calcolo se differenza in valore assoluto dei parametri di K ricavata dai due diversi metodi\n",
    "    parametri=['fx', 's', 'cx', 'fy', 'cy', 'a']\n",
    "    abs_diff=compute_absdiff(Ks,K2)\n",
    "    print('------------------------------------------')\n",
    "    print(f'Differenze parametri stimati con {n} punti:')\n",
    "    for i in range(5):\n",
    "        print(f'\\t{parametri[i]}\\t=\\t{abs_diff[i]:.6f}')\n",
    "    print('\\ta\\t=\\t16:9')\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    #Ricavo tutti i punti 2D del cubo usando la matrice P\n",
    "    all_points=punti_cubo()\n",
    "    pixels=proietta(all_points, P)\n",
    "    mostra_punti(img.copy(), pixels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb31f6f8",
   "metadata": {},
   "source": [
    "Dall'output si ricavano le differenze in modulo dei parametri, rappresentate nella seguente tabella\n",
    "\n",
    "![tabella](images/tabella.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b1a1d31",
   "metadata": {},
   "source": [
    "Per ricavare la matrice di rotazione $R$, cioè la posa della camera, si applica la formula inversa di $P_{1:3}=KR$, ovvero $R=K^{-1}P_{1:3}$, sfruttando quindi la matrice $K$ stimata in precedenza.\n",
    "\n",
    "Invece per ricavare il vettore di traslazione $t$ si sfrutta la fromula inversa della relazione\n",
    "\n",
    "![traslazione](images/formule/translation.png)\n",
    "\n",
    "quindi $t=K^{-1}P_{4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614437d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=\n",
      " [[-0.74133612  0.65393529 -0.15096153]\n",
      " [-0.32796146 -0.54923252 -0.76862535]\n",
      " [-0.58554422 -0.52030017  0.62163148]] \n",
      "\n",
      "t=\n",
      " [  2.68975572   0.68234388 -35.95904615] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calcolo Rt \n",
    "Kinv=np.linalg.inv(K)\n",
    "R=np.matmul(Kinv, P[:,0:3])\n",
    "C=np.array([[1,0,0],[0,-1,0],[0,0,1]])\n",
    "R=np.matmul(C,R)\n",
    "print(\"R=\\n\",R,\"\\n\")\n",
    "\n",
    "t=np.matmul(Kinv, P[:,3])\n",
    "t=np.matmul(C,t)\n",
    "print(\"t=\\n\", t, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f96fad66",
   "metadata": {},
   "source": [
    "Allo stesso modo del pattern, si definiscono, con il metodo ```def_punti_f``` 16 punti 3D e 2D corrispondenti nell'immagine del piano di calpestio, ovvero i punti con la coordinata $z=0$, per ricavare la nuova matrice di proiezione. In seguito si definisce, con il metodo ```punti_pav``` una griglia di punti 3D del pavimento da proiettare per ricavare, attraverso $P$, i punti 2D corrispondenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a40304ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_punti_f():\n",
    "    \n",
    "    points=np.zeros((16,3), np.float32)\n",
    "\n",
    "    points[0,:]=[0,0,0]\n",
    "    points[1,:]=[306,0,0]\n",
    "    points[2,:]=[-52,75,0]\n",
    "    points[3,:]=[127,-96,0]\n",
    "    points[4,:]=[306,-57,0]\n",
    "    points[5,:]=[306,127,0]\n",
    "    points[6,:]=[302,-96,0]\n",
    "\n",
    "    points[7,:]=[-33,-140,0]\n",
    "    points[8,:]=[22,-134,63]\n",
    "    points[9,:]=[4,-125,0]\n",
    "    points[10,:]=[306+69,36,78]\n",
    "    points[11,:]=[-68,63,80]\n",
    "    points[12,:]=[76,103,0]\n",
    "    points[13,:]=[95,113,70]\n",
    "    points[14,:]=[177,112,70]\n",
    "    points[15,:]=[176,122,0]\n",
    "\n",
    "    imgp=np.zeros((16,2), np.float32)\n",
    "\n",
    "    imgp[0,:]=[717,542]\n",
    "    imgp[1,:]=[737,209]\n",
    "    imgp[2,:]=[471,623]\n",
    "    imgp[3,:]=[946,373]\n",
    "    imgp[4,:]=[832,214]\n",
    "    imgp[5,:]=[520,201]\n",
    "    imgp[6,:]=[900,221]\n",
    "    imgp[7,:]=[1127,611]\n",
    "    imgp[8,:]=[1131,388]\n",
    "    imgp[9,:]=[1070,557]\n",
    "    imgp[10,:]=[689,52]\n",
    "    imgp[11,:]=[477,431]\n",
    "    imgp[12,:]=[476,412]\n",
    "    imgp[13,:]=[454,230]\n",
    "    imgp[14,:]=[494,156]\n",
    "    imgp[15,:]=[479,298]\n",
    "\n",
    "\n",
    "    return points, imgp\n",
    "\n",
    "def punti_pav():\n",
    "    points=np.array([[0,0,0]])\n",
    "\n",
    "    for x in range(-100, 400, 5):\n",
    "        for y in range(-200, 200, 5):\n",
    "            points=np.append(points, [np.array([x,y,0])], axis=0)\n",
    "\n",
    "    return points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "646977ee",
   "metadata": {},
   "source": [
    "Vengono richiamati i metodi precedenti per definire dei punti 3D e 2D del piano di calpestio, ricalibrare la camera per ottenere la nuova matrice $P$ e proiettare la griglia di punti del pavimento sull'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fe2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proiezione punti pavimento\n",
    "floor=cv2.imread(\"images/floor.png\")\n",
    "points, imgp = def_punti_f()\n",
    "mostra_punti(floor.copy(), imgp)\n",
    "\n",
    "_, P = calibrateDLT(points, imgp)\n",
    "\n",
    "points2=punti_pav()\n",
    "imgpoints2=proietta(points2,P)\n",
    "mostra_punti(floor.copy(), imgpoints2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "992998f2",
   "metadata": {},
   "source": [
    "Per stimare in modo migliore i vari parametri, si effettua una 4-fold cross validation, cioè si divide l'insieme dei 16 punti precedentemente definiti in due parti, un _training set_, costituito da 12 punti e utilizzato per stimare la matrice $P$, ed un _test set_, costituito dai 4 punti rimanenti e utilizzato per proiettarli ed verificare la loro posizione sull'immagine.\n",
    "\n",
    "Il procedimento viene ripetuto 4 volte, scegliendo ad ogni iterazione un _test set_ differente, e viene calcolato l'errore medio tra i punti proiettati nell'immagine e gli effettivi punti 2D. Si calcola infine l'errore medio complessivo effettuando la media degli errori, e la deviazione standard, cioè lo scostamento dal valore medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325f1677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error 1: 50.803865\n",
      "mean error 2: 56.792695\n",
      "mean error 3: 36.887938\n",
      "mean error 4: 50.582035\n",
      "Errore medio complessivo: 48.766633\n",
      "Deviazione standard errori: 7.296696\n"
     ]
    }
   ],
   "source": [
    "mean_error=[]\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(points)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(imgp)\n",
    "\n",
    "for i in range(0,13,4):\n",
    "\n",
    "    train=np.delete(points, np.s_[i:i+4], 0)\n",
    "    imgt=np.delete(imgp, np.s_[i:i+4],0)\n",
    "\n",
    "    _, P = calibrateDLT(train, imgt)\n",
    "\n",
    "    test=points[i:i+4, :]\n",
    "    pixels = proietta(test, P)\n",
    "    mostra_punti(floor.copy(), pixels)\n",
    "\n",
    "    mean_error.append((cv2.norm(imgp[i:i+4, :], pixels, normType=cv2.NORM_L2))/len(pixels))\n",
    "    print(f\"mean error {i//4+1}: {mean_error[i//4]:.6f}\")\n",
    "\n",
    "media=sum(mean_error)/len(mean_error)\n",
    "print(f\"Errore medio complessivo: {media:.6f}\")\n",
    "std=np.std(mean_error)\n",
    "print(f\"Deviazione standard errori: {std:.6f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cc9c7f8",
   "metadata": {},
   "source": [
    "Dall'output si ricavano gli errori medi per ogni fold, l'errore medio complessivo e la deviazione standard, rappresentati nella tabella seguente\n",
    "\n",
    "![tabella2](images/tabella2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
